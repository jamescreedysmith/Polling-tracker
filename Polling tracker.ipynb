{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "0aedb61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from PyPDF2 import PdfReader\n",
    "from io import BytesIO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d55b9ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewing settings\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "#pd.reset_option(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f03dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideas/to do\n",
    "\n",
    "preferred PM/leader approval - leadership approval historic? \n",
    "economic optimism\n",
    "leadership soccer styke radar charts\n",
    "blue wall vs red wall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2307eaf3",
   "metadata": {},
   "source": [
    "## Voting Intention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "id": "6a6b1fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape polling data from Pollbase\n",
    "\n",
    "pollbase_link = 'https://www.markpack.org.uk/155623/voting-intention-opinion-poll-scorecard/'\n",
    "\n",
    "link = []\n",
    "\n",
    "headers = {'User-Agent': \n",
    "           'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}\n",
    "pageTree = requests.get(pollbase_link, headers=headers)\n",
    "pageSoup = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "pollbase_poll_url = pageSoup.find_all(\"td\", {\"class\": \"has-text-align-center\"})\n",
    "link.extend(pollbase_poll_url)\n",
    "\n",
    "link = [str(item) for item in link]\n",
    "\n",
    "# extract relevant data from html code and format so that it is ready for input into dataframe\n",
    "data = []\n",
    "for i in link:\n",
    "    soup = BeautifulSoup(i, 'html.parser')\n",
    "    extracted_text = soup.get_text()\n",
    "    data.append(extracted_text)\n",
    "    \n",
    "sublists = [] # grouping every 8 items (8 variables per row)\n",
    "max_items_per_sublist = 8\n",
    "for i in range(0, len(data), max_items_per_sublist):\n",
    "    sublist = data[i:i + max_items_per_sublist]\n",
    "    sublists.append(sublist)\n",
    "    \n",
    "sublists = sublists[:-3] # delete 2015/17/19 result\n",
    "\n",
    "def remove_patterns_and_simplify_date(item):\n",
    "    # Remove patterns like (+2), (-1), and (nc)\n",
    "    cleaned_item = re.sub(r'\\(\\+\\d+\\)|\\(-\\d+\\)|\\(nc\\)', '', item)\n",
    "    \n",
    "    # Extract the simplified date and add year (e.g., '22-25/9' becomes '22/9/2023')\n",
    "    date_match = re.search(r'(\\d{1,2})-(\\d{1,2})/(\\d{1,2})', cleaned_item)\n",
    "    if date_match:\n",
    "        day_part = date_match.group(1)\n",
    "        month_part = date_match.group(3)\n",
    "        cleaned_item = f\"{day_part}/{month_part}/2024\"\n",
    "    else:\n",
    "        # 24/09 becomes 24/09/2023\n",
    "        date_match = re.search(r'(\\d{1,2})/(\\d{1,2})', cleaned_item)\n",
    "        if date_match:\n",
    "            day_part = date_match.group(1)\n",
    "            month_part = date_match.group(2)\n",
    "            cleaned_item = f\"{day_part}/{month_part}/2024\"\n",
    "    \n",
    "    return cleaned_item\n",
    "\n",
    "# Apply the function to each item in the list of lists\n",
    "cleaned_data_list_of_lists = [[remove_patterns_and_simplify_date(item) for item in sublist] for sublist in sublists]\n",
    "\n",
    "# Create a pandas DataFrame with cleaned data, convert %'s to floats and make date column a date\n",
    "\n",
    "columns = [\"Polling Company\", \"Con\", \"Lab\", \"Lib Dem\", \"Green\", \"Reform\",'Con lead', \"Date\"]\n",
    "df_latest = pd.DataFrame(cleaned_data_list_of_lists, columns=columns)\n",
    "df_latest.iloc[:, 1:7] = df_latest.iloc[:, 1:7].apply(lambda x: pd.to_numeric(x.str.rstrip('%'), errors='coerce'))\n",
    "df_latest['Date'] = pd.to_datetime(df_latest['Date'], format='%d/%m/%Y') # make datetime object\n",
    "df_latest['Date'] = df_latest['Date'].dt.strftime('%d/%m/%Y') # convert to standard date/time formatting, ready to merge datasets\n",
    "\n",
    "# create a second dataframe with historical polling data (currently up to Q4 2023)\n",
    "\n",
    "df_historical = pd.read_excel('/Users/james1/Documents/Documents/global counsel/Pollbase Q4 2023.xlsx')\n",
    "df_historical['Date'] = df_historical['Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "\n",
    "# add dataframes to create overall dataset, reset date column to datetime object with standardised formatting\n",
    "\n",
    "df_final = pd.concat([df_latest, df_historical], axis=0)\n",
    "df_final['Date'] = pd.to_datetime(df_final['Date'], format='%d/%m/%Y')\n",
    "df_final['Date'] = df_final['Date'].dt.strftime('%d/%m/%Y')\n",
    "df_final.iloc[:, 1:7] /= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "id": "f8f2598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to execute each time i want to update data\n",
    "\n",
    "pollbase_link = 'https://www.markpack.org.uk/155623/voting-intention-opinion-poll-scorecard/'\n",
    "\n",
    "link = []\n",
    "\n",
    "headers = {'User-Agent': \n",
    "           'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}\n",
    "pageTree = requests.get(pollbase_link, headers=headers)\n",
    "pageSoup = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "pollbase_poll_url = pageSoup.find_all(\"td\", {\"class\": \"has-text-align-center\"})\n",
    "link.extend(pollbase_poll_url)\n",
    "\n",
    "link = [str(item) for item in link]\n",
    "\n",
    "# extract relevant data from html code and format so that it is ready for input into dataframe\n",
    "data = []\n",
    "for i in link:\n",
    "    soup = BeautifulSoup(i, 'html.parser')\n",
    "    extracted_text = soup.get_text()\n",
    "    data.append(extracted_text)\n",
    "    \n",
    "sublists = [] # grouping every 8 items (8 variables per row)\n",
    "max_items_per_sublist = 8\n",
    "for i in range(0, len(data), max_items_per_sublist):\n",
    "    sublist = data[i:i + max_items_per_sublist]\n",
    "    sublists.append(sublist)\n",
    "    \n",
    "sublists = sublists[:-3] # delete 2015/17/19 result\n",
    "\n",
    "cleaned_data_list_of_lists = [[remove_patterns_and_simplify_date(item) for item in sublist] for sublist in sublists]\n",
    "\n",
    "\n",
    "columns = [\"Polling Company\", \"Con\", \"Lab\", \"Lib Dem\", \"Green\", \"Reform\",'Con lead', \"Date\"]\n",
    "df_latest = pd.DataFrame(cleaned_data_list_of_lists, columns=columns)\n",
    "df_latest.iloc[:, 1:7] = df_latest.iloc[:, 1:7].apply(lambda x: pd.to_numeric(x.str.rstrip('%'), errors='coerce'))\n",
    "df_latest['Date'] = pd.to_datetime(df_latest['Date'], format = '%d/%m/%Y') # make datetime object\n",
    "df_latest['Date'] = df_latest['Date'].dt.strftime('%d/%m/%Y') # convert to standard date/time formatting, ready to merge datasets\n",
    "df_latest.iloc[:, 1:7] /= 100 # divide new data by 100 so in same unit as final df\n",
    "\n",
    "# add the new latest df to the df_final that combines historical data with the 'old latest' data\n",
    "\n",
    "df_final = pd.concat([df_latest, df_final], axis=0, ignore_index=True)\n",
    "\n",
    "# sort dataframe by date\n",
    "\n",
    "df_final['Date'] = pd.to_datetime(df_final['Date'],format = '%d/%m/%Y')\n",
    "df_final = df_final.sort_values(by='Date')\n",
    "df_final['Date'] = df_final['Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# get rid of any duplicates (polls still on Pack's latest data scrape but that were scraped last time)\n",
    "\n",
    "df_final = df_final.drop_duplicates(ignore_index = True)\n",
    "\n",
    "df_final.to_excel('votingintention.xlsx', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bec383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot VI tracker graph \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig, ax = plt.subplots(figsize=(40, 24))\n",
    "\n",
    "# plot different lines\n",
    "ax.plot(df3['Date'],df3['Con'], label='Con', color='blue')\n",
    "ax.plot(df3['Date'],df3['Lab'], label='Lab', color='red')\n",
    "ax.plot(df3['Date'],df3['Lib Dem'], label='LD', color='#FFA200')\n",
    "ax.plot(df3['Date'],df3['Green'], label='Green', color='green')\n",
    "ax.plot(df3['Date'],df3['Reform'], label='Reform', color='turquoise')\n",
    "\n",
    "# formatting\n",
    "\n",
    "def percent_formatter(x, pos):\n",
    "    return f'{x*1:.0f}%'\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(percent_formatter))\n",
    "ax.yaxis.set_tick_params(labelsize=30)\n",
    "#ax.set_xticks(df3['Date'])\n",
    "#ax.set_xticklabels([date.strftime('%b %Y') for date in df3['Date']])\n",
    "ax.xaxis.set_tick_params(labelsize=30)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.25, 0.45), ncol=3, fontsize = 30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ffa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show bar chart of Conservative lead \n",
    "\n",
    "colors = ['blue' if val > 0 else 'red' for val in df3['Con lead'][:15]]\n",
    "\n",
    "# Create a figure and axis\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig, ax = plt.subplots(figsize=(20, 12))\n",
    "\n",
    "# Create the bar chart\n",
    "bars = ax.bar(df3['Date'][:15], df3['Con lead'][:15], color=colors)\n",
    "\n",
    "# Set labels and title\n",
    "\n",
    "date_format = mdates.DateFormatter('%d-%b-%Y')\n",
    "ax.xaxis.set_major_formatter(date_format)\n",
    "\n",
    "# Add labels to the bars\n",
    "for bar, val in zip(bars, df3['Con lead'][:15]):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height(),\n",
    "            str(val), ha='center', va='top', fontsize=15)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413d916a",
   "metadata": {},
   "source": [
    "## Ipsos Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "id": "24f412c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_issues_data_from_pdf(date_of_publish_str, date_str):\n",
    "    # Define the convert_date_format function\n",
    "    def convert_date_format(date_of_publish_str):\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_of_publish_str[:3]\n",
    "        year_str = '20' + date_of_publish_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its numerical representation\n",
    "        month_dict = {'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04', 'May': '05', 'Jun': '06', \n",
    "                      'Jul': '07', 'Aug': '08', 'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'}\n",
    "        month_numeric = month_dict[month_str]\n",
    "\n",
    "        # Format the date into 'YYYY-MM' format\n",
    "        formatted_date = f'{year_str}-{month_numeric}'\n",
    "        return formatted_date\n",
    "    \n",
    "    def convert_date_str_to_mmm_yy(date_str): #1: Jan24 -> jan24\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_str[:3]\n",
    "        year_str = date_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its full name\n",
    "        month_dict_lower = {'Jan': 'jan', 'Feb': 'feb', 'Mar': 'mar', 'Apr': 'apr', 'May': 'may', 'Jun': 'jun', \n",
    "                  'Jul': 'jul', 'Aug': 'aug', 'Sep': 'sep', 'Oct': 'october', 'Nov': 'nov', 'Dec': 'dec'}\n",
    "        month_lower = month_dict_lower[month_str]\n",
    "\n",
    "        # Format the date into 'mmm-year' format\n",
    "        formatted_date_lower = f'{month_lower}{year_str}'\n",
    "        return formatted_date_lower\n",
    "    \n",
    "    def convert_date_str_to_month_yy(date_str): #2 Jan24 -> january24\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_str[:3]\n",
    "        year_str = date_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its full name\n",
    "        month_dict_lower = {'Jan': 'january', 'Feb': 'february', 'Mar': 'march', 'Apr': 'april', 'May': 'may', 'Jun': 'june', \n",
    "                  'Jul': 'july', 'Aug': 'august', 'Sep': 'september', 'Oct': 'oct', 'Nov': 'november', 'Dec': 'december'}\n",
    "        month_full_name_lower = month_dict_lower[month_str]\n",
    "\n",
    "        # Format the date into 'month-year' format\n",
    "        formatted_date_lower = f'{month_full_name_lower}{year_str}'\n",
    "        return formatted_date_lower\n",
    "    \n",
    "    def convert_date_str_to_Month_yy(date_str): #3 Jan24 -> January24\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_str[:3]\n",
    "        year_str = date_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its full name\n",
    "        month_dict_upper = {'Jan': 'January', 'Feb': 'February', 'Mar': 'March', 'Apr': 'April', 'May': 'May', 'Jun': 'June', \n",
    "                  'Jul': 'July', 'Aug': 'August', 'Sep': 'September', 'Oct': 'October', 'Nov': 'November', 'Dec': 'December'}\n",
    "        month_full_name_upper = month_dict_upper[month_str]\n",
    "\n",
    "        # Format the date into 'Month-Year' format\n",
    "        formatted_date_upper = f'{month_full_name_upper}{year_str}'\n",
    "        return formatted_date_upper\n",
    "    \n",
    "    def convert_date_str_to_mmm_year(date_str): #4 Jan24 -> jan2024\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_str[:3]\n",
    "        year_str = '20' + date_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its full name\n",
    "        month_dict_lower = {'Jan': 'jan', 'Feb': 'feb', 'Mar': 'mar', 'Apr': 'apr', 'May': 'may', 'Jun': 'jun', \n",
    "                  'Jul': 'jul', 'Aug': 'aug', 'Sep': 'sep', 'Oct': 'october', 'Nov': 'nov', 'Dec': 'dec'}\n",
    "        month_lower = month_dict_lower[month_str]\n",
    "\n",
    "        # Format the date into 'month-year' format\n",
    "        formatted_date_lower = f'{month_lower}{year_str}'\n",
    "        return formatted_date_lower\n",
    "    \n",
    "    def convert_date_str_to_Mmm_year(date_str): #5 Jan24 -> Jan2024\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_str[:3]\n",
    "        year_str = '20' + date_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its full name\n",
    "        month_dict_upper = {'Jan': 'Jan', 'Feb': 'Feb', 'Mar': 'Mar', 'Apr': 'Apr', 'May': 'May', 'Jun': 'Jun', \n",
    "                  'Jul': 'Jul', 'Aug': 'Aug', 'Sep': 'Sep', 'Oct': 'Oct', 'Nov': 'Nov', 'Dec': 'Dec'}\n",
    "        month_upper = month_dict_upper[month_str]\n",
    "\n",
    "        # Format the date into 'Month-Year' format\n",
    "        formatted_date_upper = f'{month_upper}{year_str}'\n",
    "        return formatted_date_upper\n",
    "\n",
    "    def convert_date_str_to_month_year(date_str): #6 Jan24 -> january2024\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_str[:3]\n",
    "        year_str = '20' + date_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its full name\n",
    "        month_dict_lower = {'Jan': 'january', 'Feb': 'february', 'Mar': 'march', 'Apr': 'april', 'May': 'may', 'Jun': 'june', \n",
    "                  'Jul': 'july', 'Aug': 'august', 'Sep': 'september', 'Oct': 'october', 'Nov': 'november', 'Dec': 'december'}\n",
    "        month_full_name_lower = month_dict_lower[month_str]\n",
    "\n",
    "        # Format the date into 'month-year' format\n",
    "        formatted_date_lower = f'{month_full_name_lower}{year_str}'\n",
    "        return formatted_date_lower\n",
    "        \n",
    "    def convert_date_str_to_Month_year(date_str): #7 Jan24 -> January2024\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_str[:3]\n",
    "        year_str = '20' + date_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its full name\n",
    "        month_dict_upper = {'Jan': 'January', 'Feb': 'February', 'Mar': 'March', 'Apr': 'April', 'May': 'May', 'Jun': 'June', \n",
    "                  'Jul': 'July', 'Aug': 'August', 'Sep': 'September', 'Oct': 'October', 'Nov': 'November', 'Dec': 'December'}\n",
    "        month_full_name_upper = month_dict_upper[month_str]\n",
    "\n",
    "        # Format the date into 'Month-Year' format\n",
    "        formatted_date_upper = f'{month_full_name_upper}{year_str}'\n",
    "        return formatted_date_upper\n",
    "    \n",
    "    \n",
    "    def convert_date_str_to_month_dash_year (date_str): #8 Jan24 -> january-2024\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_str[:3]\n",
    "        year_str = '20' + date_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its full name\n",
    "        month_dict_lower = {'Jan': 'january', 'Feb': 'february', 'Mar': 'march', 'Apr': 'april', 'May': 'may', 'Jun': 'june', \n",
    "                  'Jul': 'july', 'Aug': 'august', 'Sep': 'september', 'Oct': 'october', 'Nov': 'november', 'Dec': 'december'}\n",
    "        month_full_name_lower = month_dict_lower[month_str]\n",
    "\n",
    "        # Format the date into 'month-year' format\n",
    "        formatted_date_lower = f'{month_full_name_lower}-{year_str}'\n",
    "        return formatted_date_lower\n",
    "    \n",
    "    def convert_date_str_to_mmm_dash_year (date_str): #9 Jan24 -> jan-2024\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_str[:3]\n",
    "        year_str = '20' + date_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its full name\n",
    "        month_dict_lower = {'Jan': 'jan', 'Feb': 'feb', 'Mar': 'mar', 'Apr': 'apr', 'May': 'may', 'Jun': 'jun', \n",
    "                  'Jul': 'jul', 'Aug': 'aug', 'Sep': 'sep', 'Oct': 'oct', 'Nov': 'nov', 'Dec': 'dec'}\n",
    "        month_lower = month_dict_lower[month_str]\n",
    "\n",
    "        # Format the date into 'month-year' format\n",
    "        formatted_date_lower = f'{month_lower}-{year_str}'\n",
    "        return formatted_date_lower\n",
    "    \n",
    "    # Convert date_of publish_str to 'YYYY-MM' format\n",
    "    formatted_date_of_publish_str = convert_date_format(date_of_publish_str)\n",
    "    \n",
    "    # Convert date_str to MM/YYYY format for the date column of data frame\n",
    "    date_obj = datetime.strptime(date_str, '%b%y')\n",
    "    formatted_date_str = date_obj.strftime('%m/%Y')\n",
    "    \n",
    "    # Convert date_str into all different formats for scraping \n",
    "    date_str_lower_year = convert_date_str_to_mmm_year(date_str) # Jan24 -> jan2024\n",
    "    date_str_lower_full_month_year = convert_date_str_to_month_year(date_str) #Jan24 -> january2024\n",
    "    date_str_full_month_year = convert_date_str_to_Month_year(date_str) #Jan24 -> January2024\n",
    "    date_str_upper_year = convert_date_str_to_Mmm_year(date_str) #Jan24 -> Jan2024\n",
    "    date_str_lower_yy = convert_date_str_to_mmm_yy(date_str) #Jan24 -> jan24\n",
    "    date_str_lower_full_month_yy = convert_date_str_to_month_yy(date_str) #Jan24 -> january24\n",
    "    date_str_full_month_yy = convert_date_str_to_Month_yy(date_str) #Jan24 -> January24\n",
    "    date_str_lower_full_month_dash_year = convert_date_str_to_month_dash_year(date_str) #Jan24 -> january-2024\n",
    "    date_str_lower_dash_year = convert_date_str_to_mmm_dash_year(date_str) #Jan24 -> jan-2024\n",
    "\n",
    "    # List of possible URL formats\n",
    "    url_formats = [\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str}_Issues%20Index_topline_PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str}_Issues%20Index_topline_PUBLIC_0.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_lower_year}_Issues%20Index_topline_PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_lower_full_month_year}_Issues%20Index_topline_PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_full_month_year}_Issues%20Index_topline_PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_upper_year}_Issues%20Index_topline_PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_lower_yy}_Issues%20Index_topline_PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_lower_full_month_yy}_Issues%20Index_topline_PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_full_month_yy}_Issues%20Index_topline_PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/ipsos-issues-index-{date_str_lower_full_month_dash_year}-topline.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/ipsos-issues-index-{date_str_lower_full_month_dash_year}-topline-PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/ipsos-issues-index-{date_str_lower_dash_year}-topline.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/ipsos-issues-index-{date_str_lower_dash_year}-topline-PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/ipsos-issues-index-topline-{date_str_lower_dash_year}.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/ipsos-issues-index-topline-{date_str_lower_full_month_dash_year}.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/issues-index-{date_str_lower_full_month_dash_year}-topline.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/issues-index-{date_str_lower_dash_year}-topline.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/issues-index-{date_str_lower_full_month_dash_year}-topline-PUBLIC.pdf',  \n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/issues-index-{date_str_lower_dash_year}-topline-PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/issues-index-topline-{date_str_lower_dash_year}.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/issues-index-topline-{date_str_lower_full_month_dash_year}.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str}_issues_index_topline_public.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str}_issues_index_topline.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_lower_year}_issues_index_topline_public.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_lower_full_month_year}_issues_index_topline_public.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_full_month_year}_issues_index_topline_public.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_upper_year}_issues_index_topline_public.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_lower_yy}_issues_index_topline_public.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_lower_full_month_yy}_issues_index_topline_public.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_full_month_yy}_issues_index_topline_public.pdf'\n",
    "    ]\n",
    "        \n",
    "    \n",
    "    # Attempt to retrieve the PDF content from each URL\n",
    "    for pdf_url in url_formats:\n",
    "        response = requests.get(pdf_url)\n",
    "        if response.status_code == 200:\n",
    "            pdf_file = PyPDF2.PdfReader(BytesIO(response.content))\n",
    "            break  # Break out of the loop if PDF content is successfully retrieved\n",
    "    \n",
    "    # If PDF content couldn't be retrieved, handle the error or return None\n",
    "    else:\n",
    "        print(response.status_code, pdf_url)\n",
    "        return None\n",
    "    \n",
    "    # Get the PDF content\n",
    "    #response = requests.get(pdf_url)\n",
    "    #pdf_file = PyPDF2.PdfReader(BytesIO(response.content))\n",
    "    \n",
    "     # Extract text from each page of the PDF\n",
    "    for page_number in range(len(pdf_file.pages)):\n",
    "        page_text = pdf_file.pages[page_number].extract_text()\n",
    "    rows = [line.split() for line in page_text.split('\\n') if line.strip()]\n",
    "    rows = rows[10:]\n",
    "    \n",
    "    # Rearrange each sublist\n",
    "    def rearrange_sublist(sublist):\n",
    "        variable_names = ' '.join(sublist[:-2])\n",
    "        first_value = sublist[-2] if len(sublist) >= 2 else ''\n",
    "        second_value = sublist[-1] if len(sublist) >= 1 else ''\n",
    "        return [variable_names, first_value, second_value]\n",
    "\n",
    "    rearranged_data = [rearrange_sublist(sublist) for sublist in rows]\n",
    "\n",
    "    \n",
    "    # Convert the rearranged data into a DataFrame\n",
    "    df = pd.DataFrame(rearranged_data, columns=['Variable Names', 'Most important issue', 'One of the most important  issues'])\n",
    "    df = df.drop(columns=['Most important issue'])\n",
    "    df['Date'] = formatted_date_str  # Add a 'Date' column with the formatted date\n",
    "    df = df.pivot(columns='Variable Names', values='One of the most important  issues', index='Date')\n",
    "\n",
    "    # Reset the index to make 'Date' a column\n",
    "    df = df.reset_index()\n",
    "    df = df.rename_axis('Index', axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60e9c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_issues_data_from_pdf_url(date, url_str):\n",
    "    global ipsos_issues_df\n",
    "    # Convert date_str to MM/YYYY format\n",
    "    date_obj = datetime.strptime(date_str, '%b%y')\n",
    "    formatted_date_str = date_obj.strftime('%m/%Y')\n",
    "\n",
    "    # Construct the URL with the given date string\n",
    "    pdf_url = url_str\n",
    "    \n",
    "    # Get the PDF content\n",
    "    response = requests.get(pdf_url)\n",
    "    pdf_file = PyPDF2.PdfReader(BytesIO(response.content))\n",
    "    \n",
    "   # Extract text from each page of the PDF\n",
    "    for page_number in range(len(pdf_file.pages)):\n",
    "        page_text = pdf_file.pages[page_number].extract_text()\n",
    "    rows = [line.split() for line in page_text.split('\\n') if line.strip()]\n",
    "    rows = rows[10:]\n",
    "    \n",
    "    # Rearrange each sublist\n",
    "    def rearrange_sublist(sublist):\n",
    "        variable_names = ' '.join(sublist[:-2])\n",
    "        first_value = sublist[-2] if len(sublist) >= 2 else ''\n",
    "        second_value = sublist[-1] if len(sublist) >= 1 else ''\n",
    "        return [variable_names, first_value, second_value]\n",
    "\n",
    "    rearranged_data = [rearrange_sublist(sublist) for sublist in rows]\n",
    "\n",
    "    # Convert the rearranged data into a DataFrame\n",
    "    df = pd.DataFrame(rearranged_data, columns=['Variable Names', 'Most important issue', 'One of the most important  issues'])\n",
    "    df = df.drop(columns='Most important issue')\n",
    "    df = df.rename(columns={'One of the most important  issues': date})\n",
    "    df = df.set_index('Variable Names').T\n",
    "    df = df.rename_axis('Date', axis=1)\n",
    "    \n",
    "    ipsos_issues_df = ipsos_issues_df.append(df)\n",
    "    \n",
    "    return ipsos_issues_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "id": "30ec6048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of tuples containing pairs of dates from Jan 2020 to Jan 2024\n",
    "\n",
    "date_pairs_2019 = [('Jan19', 'Jan19'), ('Feb19', 'Jan19'), ('Feb19', 'Feb19'),\n",
    "    ('Mar19', 'Feb19'), ('Mar19', 'Mar19'), ('Apr19', 'Mar19'), ('Apr19', 'Apr19'), ('May19', 'Apr19'),\n",
    "    ('May19', 'May19'), ('Jun19', 'May19'), ('Jun19', 'Jun19'), ('Jul19', 'Jun19'), ('Jul19', 'Jul19'),\n",
    "    ('Aug19', 'Jul19'), ('Aug19', 'Aug19'), ('Sep19', 'Aug19'), ('Sep19', 'Sep19'), ('Oct19', 'Sep19'),\n",
    "    ('Oct19', 'Oct19'), ('Nov19', 'Oct19'), ('Nov19', 'Nov19'), ('Dec19', 'Nov19'), ('Dec19', 'Dec19'),\n",
    "    ('Jan20', 'Dec19')]\n",
    "\n",
    "date_pairs_2020 = [\n",
    "    ('Jan20', 'Jan20'), ('Feb20', 'Jan20'), ('Feb20', 'Feb20'), ('Mar20', 'Feb20'), ('Mar20', 'Mar20'),\n",
    "    ('Apr20', 'Mar20'), ('Apr20', 'Apr20'), ('May20', 'Apr20'), ('May20', 'May20'), ('Jun20', 'May20'),\n",
    "    ('Jun20', 'Jun20'), ('Jul20', 'Jun20'), ('Jul20', 'Jul20'), ('Aug20', 'Jul20'), ('Aug20', 'Aug20'),\n",
    "    ('Sep20', 'Aug20'), ('Sep20', 'Sep20'), ('Oct20', 'Sep20'), ('Oct20', 'Oct20'), ('Nov20', 'Oct20'),\n",
    "    ('Nov20', 'Nov20'), ('Dec20', 'Nov20'), ('Dec20', 'Dec20'), ('Jan21', 'Dec20')]\n",
    "\n",
    "date_pairs_2021 = [('Jan21', 'Jan21'),\n",
    "    ('Feb21', 'Jan21'), ('Feb21', 'Feb21'), ('Mar21', 'Feb21'), ('Mar21', 'Mar21'), ('Apr21', 'Mar21'),\n",
    "    ('Apr21', 'Apr21'), ('May21', 'Apr21'), ('May21', 'May21'), ('Jun21', 'May21'), ('Jun21', 'Jun21'),\n",
    "    ('Jul21', 'Jun21'), ('Jul21', 'Jul21'), ('Aug21', 'Jul21'), ('Aug21', 'Aug21'), ('Sep21', 'Aug21'),\n",
    "    ('Sep21', 'Sep21'), ('Oct21', 'Sep21'), ('Oct21', 'Oct21'), ('Nov21', 'Oct21'), ('Nov21', 'Nov21'),\n",
    "    ('Dec21', 'Nov21'), ('Dec21', 'Dec21'), ('Jan22', 'Dec21')]\n",
    "\n",
    "date_pairs_2022 = [('Jan22', 'Jan22'), ('Feb22', 'Jan22'),\n",
    "    ('Feb22', 'Feb22'), ('Mar22', 'Feb22'), ('Mar22', 'Mar22'), ('Apr22', 'Mar22'), ('Apr22', 'Apr22'),\n",
    "    ('May22', 'Apr22'), ('May22', 'May22'), ('Jun22', 'May22'), ('Jun22', 'Jun22'), ('Jul22', 'Jun22'),\n",
    "    ('Jul22', 'Jul22'), ('Aug22', 'Jul22'), ('Aug22', 'Aug22'), ('Sep22', 'Aug22'), ('Sep22', 'Sep22'),\n",
    "    ('Oct22', 'Sep22'), ('Oct22', 'Oct22'), ('Nov22', 'Oct22'), ('Nov22', 'Nov22'), ('Dec22', 'Nov22'),\n",
    "    ('Dec22', 'Dec22'), ('Jan23', 'Dec22')]\n",
    "\n",
    "date_pairs_2023 = [('Jan23', 'Jan23'), ('Feb23', 'Jan23'), ('Feb23', 'Feb23'),\n",
    "    ('Mar23', 'Feb23'), ('Mar23', 'Mar23'), ('Apr23', 'Mar23'), ('Apr23', 'Apr23'), ('May23', 'Apr23'),\n",
    "    ('May23', 'May23'), ('Jun23', 'May23'), ('Jun23', 'Jun23'), ('Jul23', 'Jun23'), ('Jul23', 'Jul23'),\n",
    "    ('Aug23', 'Jul23'), ('Aug23', 'Aug23'), ('Sep23', 'Aug23'), ('Sep23', 'Sep23'), ('Oct23', 'Sep23'),\n",
    "    ('Oct23', 'Oct23'), ('Nov23', 'Oct23'), ('Nov23', 'Nov23'), ('Dec23', 'Nov23'), ('Dec23', 'Dec23'),\n",
    "    ('Jan24', 'Dec23')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "id": "b1b0f263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2019-01/January19_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2019-02/January19_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2019-02/February19_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2019-04/March19_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2019-04/April19_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2019-06/May19_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2019-06/June19_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2019-07/July19_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2019-08/July19_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2019-08/August19_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2019-09/September19_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2019-10/September19_issues_index_topline_public.pdf\n",
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2019-10/October19_issues_index_topline_public.pdf\n",
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2019-11/October19_issues_index_topline_public.pdf\n",
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2019-11/November19_issues_index_topline_public.pdf\n",
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2019-12/November19_issues_index_topline_public.pdf\n",
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2019-12/December19_issues_index_topline_public.pdf\n",
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-01/December19_issues_index_topline_public.pdf\n"
     ]
    }
   ],
   "source": [
    "ipsos_issues_combined_df_2019 = pd.DataFrame()\n",
    "\n",
    "# Loop through the dates list and process each date\n",
    "for date_of_publish_str, date_str in date_pairs_2019:\n",
    "    try:\n",
    "        # Call the function to get brexit data for the current date\n",
    "        ipsos_issues_df_2019 = get_issues_data_from_pdf(date_of_publish_str, date_str)\n",
    "        \n",
    "        # Append the current date's data to the combined DataFrame\n",
    "        ipsos_issues_combined_df_2019 = ipsos_issues_combined_df_2019.append(ipsos_issues_df_2019, ignore_index= False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for date: {date_str}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "id": "6b78713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-01/January20_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-02/February20_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-03/February20_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-03/March20_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-04/March20_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-05/April20_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-05/May20_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-06/May20_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-07/June20_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-07/July20_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-08/July20_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-08/August20_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-09/August20_issues_index_topline_public.pdf\n",
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-09/September20_issues_index_topline_public.pdf\n",
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-10/September20_issues_index_topline_public.pdf\n",
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-10/October20_issues_index_topline_public.pdf\n",
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-11/October20_issues_index_topline_public.pdf\n",
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-11/November20_issues_index_topline_public.pdf\n",
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-12/November20_issues_index_topline_public.pdf\n",
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-12/December20_issues_index_topline_public.pdf\n",
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2021-01/December20_issues_index_topline_public.pdf\n"
     ]
    }
   ],
   "source": [
    "ipsos_issues_combined_df_2020 = pd.DataFrame()\n",
    "\n",
    "#Loop through the dates list and process each date\n",
    "\n",
    "for date_of_publish_str, date_str in date_pairs_2020:\n",
    "    try:\n",
    "        # Call the function to get brexit data for the current date\n",
    "        ipsos_issues_df_2020 = get_issues_data_from_pdf(date_of_publish_str, date_str)\n",
    "        \n",
    "        # Append the current date's data to the combined DataFrame\n",
    "        ipsos_issues_combined_df_2020 = ipsos_issues_combined_df_2020.append(ipsos_issues_df_2020, ignore_index= False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for date: {date_str}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "id": "1b5de875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-10/September20_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-10/October20_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-11/November20_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-12/December20_issues_index_topline_public.pdf\n"
     ]
    }
   ],
   "source": [
    "date_pairs_2020_second_half = [('Sep20','Sep20'),('Oct20', 'Sep20'), ('Oct20', 'Oct20'), ('Nov20', 'Oct20'),\n",
    "    ('Nov20', 'Nov20'), ('Dec20', 'Nov20'), ('Dec20', 'Dec20'), ('Jan21', 'Dec20')]\n",
    "\n",
    "# Loop through the dates list and process each date\n",
    "for date_of_publish_str, date_str in date_pairs_2020_second_half:\n",
    "    try:\n",
    "        # Call the function to get brexit data for the current date\n",
    "        ipsos_issues_df_2020 = get_issues_data_from_pdf(date_of_publish_str, date_str)\n",
    "        \n",
    "        # Append the current date's data to the combined DataFrame\n",
    "        ipsos_issues_combined_df_2020 = ipsos_issues_combined_df_2020.append(ipsos_issues_df_2020, ignore_index= True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for date: {date_str}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "id": "699f84a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2021-01/January21_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2021-02/February21_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2021-04/March21_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2021-04/April21_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2021-05/April21_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2021-05/May21_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2021-06/May21_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2021-06/June21_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2021-07/July21_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2021-09/August21_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2021-10/September21_issues_index_topline_public.pdf\n",
      "404 https://www.ipsos.com/sites/default/files/ct/news/documents/2021-11/October21_issues_index_topline_public.pdf\n",
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2021-12/November21_issues_index_topline_public.pdf\n",
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2021-12/December21_issues_index_topline_public.pdf\n",
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2022-01/December21_issues_index_topline_public.pdf\n"
     ]
    }
   ],
   "source": [
    "ipsos_issues_combined_df_2021 = pd.DataFrame()\n",
    "\n",
    "# Loop through the dates list and process each date\n",
    "for date_of_publish_str, date_str in date_pairs_2021:\n",
    "    try:\n",
    "        # Call the function to get brexit data for the current date\n",
    "        ipsos_issues_df_2021 = get_issues_data_from_pdf(date_of_publish_str, date_str)\n",
    "        \n",
    "        # Append the current date's data to the combined DataFrame\n",
    "        ipsos_issues_combined_df_2021 = ipsos_issues_combined_df_2021.append(ipsos_issues_df_2021, ignore_index= True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for date: {date_str}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1311,
   "id": "866d18d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-09/September20_issues_index_topline_public.pdf\n",
      "429 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-10/September20_issues_index_topline_public.pdf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1311-cd90031f5f46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Call the function to get brexit data for the current date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mipsos_issues_df_2021\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_issues_data_from_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_of_publish_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Append the current date's data to the combined DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1287-d93c87a42144>\u001b[0m in \u001b[0;36mget_issues_data_from_pdf\u001b[0;34m(date_of_publish_str, date_str)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;31m# Attempt to retrieve the PDF content from each URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpdf_url\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl_formats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mpdf_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyPDF2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPdfReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "date_pairs_2021_second_half = [('Sep21','Sep21'),('Oct21', 'Oct21'), ('Nov21', 'Oct21'),\n",
    "    ('Nov21', 'Nov21'), ('Dec21', 'Nov21'), ('Dec21', 'Dec21'), ('Jan22', 'Dec21')]\n",
    "\n",
    "# Loop through the dates list and process each date\n",
    "for date_of_publish_str, date_str in date_pairs_2021_second_half:\n",
    "    try:\n",
    "        # Call the function to get brexit data for the current date\n",
    "        ipsos_issues_df_2021 = get_issues_data_from_pdf(date_of_publish_str, date_str)\n",
    "        \n",
    "        # Append the current date's data to the combined DataFrame\n",
    "        ipsos_issues_combined_df_2021 = ipsos_issues_combined_df_2021.append(ipsos_issues_df_2021, ignore_index= True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for date: {date_str}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b5ce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipsos_issues_combined_df_2022 = pd.DataFrame()\n",
    "\n",
    "# Loop through the dates list and process each date\n",
    "for date_of_publish_str, date_str in date_pairs_2022:\n",
    "    try:\n",
    "        # Call the function to get brexit data for the current date\n",
    "        ipsos_issues_df_2022 = get_issues_data_from_pdf(date_of_publish_str, date_str)\n",
    "        \n",
    "        # Append the current date's data to the combined DataFrame\n",
    "        ipsos_issues_combined_df_2022 = ipsos_issues_combined_df_2022.append(ipsos_issues_df_2022, ignore_index= True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for date: {date_str}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bfc87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_pairs_2022_second_half = [('Sep22','Sep22'),('Oct22', 'Oct22'), ('Nov22', 'Oct22'), ('Nov22', 'Nov22'), ('Dec22', 'Nov22'),\n",
    "    ('Dec22', 'Dec22'), ('Jan23', 'Dec22')]\n",
    "\n",
    "# Loop through the dates list and process each date\n",
    "for date_of_publish_str, date_str in date_pairs_2020_second_half:\n",
    "    try:\n",
    "        # Call the function to get brexit data for the current date\n",
    "        ipsos_issues_df_2022 = get_issues_data_from_pdf(date_of_publish_str, date_str)\n",
    "        \n",
    "        # Append the current date's data to the combined DataFrame\n",
    "        ipsos_issues_combined_df_2022 = ipsos_issues_combined_df_2022.append(ipsos_issues_df_2022, ignore_index= True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for date: {date_str}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bba26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipsos_issues_combined_df_2023 = pd.DataFrame()\n",
    "\n",
    "# Loop through the dates list and process each date\n",
    "for date_of_publish_str, date_str in date_pairs_2023:\n",
    "    try:\n",
    "        # Call the function to get brexit data for the current date\n",
    "        ipsos_issues_df_2023 = get_issues_data_from_pdf(date_of_publish_str, date_str)\n",
    "        \n",
    "        # Append the current date's data to the combined DataFrame\n",
    "        ipsos_issues_combined_df_2023 = ipsos_issues_combined_df_2023.append(ipsos_issues_df_2023, ignore_index= True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for date: {date_str}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_pairs_2023_second_half = [('Sep23','Sep23'),('Oct23', 'Sep23'),('Oct23', 'Oct23'), ('Nov23', 'Oct23'), ('Nov23', 'Nov23'), ('Dec23', 'Nov23'), ('Dec23', 'Dec23'),\n",
    "    ('Jan24', 'Dec23')]\n",
    "\n",
    "# Loop through the dates list and process each date\n",
    "for date_of_publish_str, date_str in date_pairs_2023_second_half:\n",
    "    try:\n",
    "        # Call the function to get brexit data for the current date\n",
    "        ipsos_issues_df_2023 = get_issues_data_from_pdf(date_of_publish_str, date_str)\n",
    "        \n",
    "        # Append the current date's data to the combined DataFrame\n",
    "        ipsos_issues_combined_df_2023 = ipsos_issues_combined_df_2023.append(ipsos_issues_df_2023, ignore_index= True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for date: {date_str}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "id": "ce7ba30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipsos_issues_df = pd.concat([ipsos_issues_combined_df_2020, ipsos_issues_combined_df_2021, ipsos_issues_combined_df_2022, \n",
    "                             ipsos_issues_combined_df_2023, ipsos_issues_df_2024], ignore_index = True)\n",
    "\n",
    "# Months i couldn't scrape: Apr 21; May 21; Dec 22; Feb23 (all no topline); dec 2023 (weird url); \n",
    "# aug 2020, jul2020, may 2020, mar 2020 (all didn't do one), feb 2020 (released 2 months ahead); Jan 2019 and Aug 2019\n",
    "\n",
    "# receiving data from urls \n",
    "\n",
    "# feb 2020: https://www.ipsos.com/sites/default/files/ct/news/documents/2020-04/february20_issues_index_topline_public.pdf\n",
    "\n",
    "# receiving data from chart pdfs\n",
    "\n",
    "# formatting (to do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0edafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#. sort dataframe by date\n",
    "\n",
    "#ipsos_issues_df.reset_index(inplace=True)\n",
    "#ipsos_issues_df['index'] = pd.to_datetime(ipsos_issues_df['index'])\n",
    "#ipsos_issues_df = ipsos_issues_df.drop(columns = 'level_0')\n",
    "ipsos_issues_df = ipsos_issues_df.sort_values(by='index')\n",
    "ipsos_issues_df['index'] = ipsos_issues_df['index'].dt.strftime('%m/%Y')\n",
    "ipsos_issues_df.set_index('index', inplace=True)\n",
    "#flip so nearest date at top: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c16396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to add new data: either try scraping data or if that doesnt work add by url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb3694",
   "metadata": {},
   "source": [
    "# Best PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ec2197",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pm_link = 'https://wethink.netlify.app/'\n",
    "\n",
    "link = []\n",
    "\n",
    "headers = {'User-Agent': \n",
    "           'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}\n",
    "pageTree = requests.get(best_pm_link, headers=headers)\n",
    "pageSoup = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "best_pm_url = pageSoup.find_all('div', {'class': 'flex flex-col gap-y-5 items-start'})\n",
    "\n",
    "dates = []\n",
    "for time_tag in pageSoup.find_all('time', {'datetime': True}):\n",
    "    dates.append(time_tag['datetime'])\n",
    "date = dates[0]\n",
    "\n",
    "\n",
    "scraped_data = pageSoup.find_all('p', class_='!mb-0')\n",
    "\n",
    "string_list = [tag.get_text() for tag in scraped_data]\n",
    "\n",
    "cleaned_data = [s.split(' (')[0] for s in string_list]\n",
    "\n",
    "\n",
    "keir_starmer = 0\n",
    "rishi_sunak = 0\n",
    "dont_know = 0\n",
    "\n",
    "\n",
    "# Iterate over the data list\n",
    "for i in range(len(cleaned_data)):\n",
    "    # Check if the string contains the name and percentage\n",
    "    if 'Sir Keir Starmer' in cleaned_data[i]:\n",
    "        keir_starmer = int(cleaned_data[i-1])\n",
    "    elif 'Rishi Sunak' in cleaned_data[i]:\n",
    "        rishi_sunak = int(cleaned_data[i-1])\n",
    "    elif \"Don't Know\" in cleaned_data[i]:\n",
    "        dont_know = int(cleaned_data[i-1])\n",
    "        \n",
    "best_pm_df_latest = {\"Date\": date,\n",
    "        'Keir Starmer': [keir_starmer],\n",
    "        'Rishi Sunak': [rishi_sunak],\n",
    "        \"Don't know\": [dont_know]}\n",
    "\n",
    "best_pm_df_latest = pd.DataFrame(best_pm_df_latest)\n",
    "best_pm_df_latest['Date'] = pd.to_datetime(best_pm_df_latest['Date'])\n",
    "best_pm_df_latest['Date'] = best_pm_df_latest['Date'].dt.strftime('%d-%m-%Y')\n",
    "best_pm_df_latest.iloc[:, 1:7] /= 100\n",
    "\n",
    "best_pm_df_historical = pd.read_excel('/Users/james1/Documents/Documents/global counsel/Best_pm_historical_data.xlsx')\n",
    "best_pm_df_historical['Date'] = best_pm_df_historical['Date'].dt.strftime('%d-%m-%Y')\n",
    "best_pm_df_final = pd.concat([best_pm_df_latest, best_pm_df_historical], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af8f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for adding new data\n",
    "\n",
    "best_pm_link = 'https://wethink.netlify.app/'\n",
    "\n",
    "link = []\n",
    "\n",
    "headers = {'User-Agent': \n",
    "           'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}\n",
    "pageTree = requests.get(best_pm_link, headers=headers)\n",
    "pageSoup = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "best_pm_url = pageSoup.find_all('div', {'class': 'flex flex-col gap-y-5 items-start'})\n",
    "\n",
    "dates = []\n",
    "for time_tag in pageSoup.find_all('time', {'datetime': True}):\n",
    "    dates.append(time_tag['datetime'])\n",
    "date = dates[0]\n",
    "\n",
    "\n",
    "scraped_data = pageSoup.find_all('p', class_='!mb-0')\n",
    "\n",
    "string_list = [tag.get_text() for tag in scraped_data]\n",
    "\n",
    "cleaned_data = [s.split(' (')[0] for s in string_list]\n",
    "\n",
    "\n",
    "keir_starmer = 0\n",
    "rishi_sunak = 0\n",
    "dont_know = 0\n",
    "\n",
    "\n",
    "# Iterate over the data list\n",
    "for i in range(len(cleaned_data)):\n",
    "    # Check if the string contains the name and percentage\n",
    "    if 'Sir Keir Starmer' in cleaned_data[i]:\n",
    "        keir_starmer = int(cleaned_data[i-1])\n",
    "    elif 'Rishi Sunak' in cleaned_data[i]:\n",
    "        rishi_sunak = int(cleaned_data[i-1])\n",
    "    elif \"Don't Know\" in cleaned_data[i]:\n",
    "        dont_know = int(cleaned_data[i-1])\n",
    "        \n",
    "best_pm_df_latest = {\"Date\": date,\n",
    "        'Keir Starmer': [keir_starmer],\n",
    "        'Rishi Sunak': [rishi_sunak],\n",
    "        \"Don't know\": [dont_know]}\n",
    "\n",
    "best_pm_df_latest = pd.DataFrame(best_pm_df_latest)\n",
    "best_pm_df_latest['Date'] = pd.to_datetime(best_pm_df_latest['Date'])\n",
    "best_pm_df_latest['Date'] = best_pm_df_latest['Date'].dt.strftime('%d-%m-%Y')\n",
    "best_pm_df_latest.iloc[:, 1:7] /= 100\n",
    "\n",
    "best_pm_df_final = pd.concat([best_pm_df_latest,best_pm_df_final], axis = 0, ignore_index = True)\n",
    "\n",
    "# sort dataframe by date\n",
    "\n",
    "best_pm_df_final['Date'] = pd.to_datetime(best_pm_df_final['Date'],format = '%d-%m-%Y')\n",
    "best_pm_df_final = best_pm_df_final.sort_values(by='Date')\n",
    "best_pm_df_final['Date'] = best_pm_df_final['Date'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "# get rid of any duplicates \n",
    "\n",
    "best_pm_df_final = best_pm_df_final.drop_duplicates(ignore_index = True)\n",
    "\n",
    "best_pm_df_final.to_excel('bestpm.xlsx', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da339d5",
   "metadata": {},
   "source": [
    "# Economy and Brexit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c19c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define get brexit and economy data function \n",
    "\n",
    "def get_brexit_and_economy_delta_data(date_str):\n",
    "    # Convert date string to different formats\n",
    "    formatted_date_YM = date_str[6:] + '/' + date_str[3:5]\n",
    "    formatted_date_YMD = date_str[8:] + date_str[3:5] + date_str[:2]\n",
    "\n",
    "    # Construct PDF URL\n",
    "    pdf_url = f'https://deltapoll.co.uk/wp-content/uploads/{formatted_date_YM}/Deltapoll-{formatted_date_YMD}_trackers.pdf'\n",
    "\n",
    "    #  # Retrieve PDF content\n",
    "    response = requests.get(pdf_url)\n",
    "    pdf_file = PdfReader(BytesIO(response.content))\n",
    "    page_text = pdf_file.pages[-1].extract_text()\n",
    "\n",
    "    # Split text into sections\n",
    "    sections = page_text.split('\\n')\n",
    "\n",
    "    # Trim data\n",
    "    trimmed_data = []\n",
    "    for item in sections:\n",
    "        if 'Excluding' in item:\n",
    "            break\n",
    "        trimmed_data.append(item)\n",
    "\n",
    "    trimmed_data = [item for item in trimmed_data if any(char.isdigit() for char in item)]\n",
    "\n",
    "    # Initialize lists to hold extracted data\n",
    "    conservative_number = []\n",
    "    labour_number = []\n",
    "    dont_know_economy = []\n",
    "    stay_out_eu = []\n",
    "    rejoin_eu = []\n",
    "    dont_know_brexit = []\n",
    "\n",
    "    # Extract data\n",
    "    for item in trimmed_data:\n",
    "        if 'Exchequer' in item:\n",
    "            number = ''.join(filter(str.isdigit, item))\n",
    "            if not conservative_number:\n",
    "                conservative_number.append(number)\n",
    "            else:\n",
    "                labour_number.append(number)\n",
    "        elif \"Don't know\" in item:\n",
    "            number = ''.join(filter(str.isdigit, item))\n",
    "            if not dont_know_economy:\n",
    "                dont_know_economy.append(number)\n",
    "            else:\n",
    "                dont_know_brexit.append(number)\n",
    "        elif 'European Union' in item:\n",
    "            number = ''.join(filter(str.isdigit, item))\n",
    "            if not stay_out_eu:\n",
    "                stay_out_eu.append(number)\n",
    "            else:\n",
    "                rejoin_eu.append(number)\n",
    "\n",
    "    # Create data dictionaries\n",
    "    brexit_economy_data = {\n",
    "        'Conservatives/Rishi Sunak/Jeremy Hunt': conservative_number,\n",
    "        'Labour/Keir Starmer/Rachel Reeves': labour_number,\n",
    "        'Don\\'t Know econ': dont_know_economy,\n",
    "        'Rejoin EU': rejoin_eu,\n",
    "        'Stay Out EU': stay_out_eu,\n",
    "        'Don\\'t Know brex': dont_know_brexit\n",
    "    }\n",
    "\n",
    "    # Create dataframes\n",
    "    brexit_economy_df = pd.DataFrame(brexit_economy_data)\n",
    "    brexit_economy_df['Conservatives/Rishi Sunak/Jeremy Hunt'] = pd.to_numeric(brexit_economy_df['Conservatives/Rishi Sunak/Jeremy Hunt'])\n",
    "    brexit_economy_df['Labour/Keir Starmer/Rachel Reeves'] = pd.to_numeric(brexit_economy_df['Labour/Keir Starmer/Rachel Reeves'])\n",
    "    brexit_economy_df['Don\\'t Know econ'] = pd.to_numeric(brexit_economy_df['Don\\'t Know econ'])\n",
    "    brexit_economy_df['Stay Out EU'] =  pd.to_numeric(brexit_economy_df['Stay Out EU'])\n",
    "    brexit_economy_df['Rejoin EU'] =  pd.to_numeric(brexit_economy_df['Rejoin EU'])\n",
    "    brexit_economy_df['Don\\'t Know brex'] =  pd.to_numeric(brexit_economy_df['Don\\'t Know brex'])\n",
    "\n",
    "    # Add Date column to dataframes\n",
    "    date = pd.to_datetime(date_str)\n",
    "    formatted_date = date.strftime('%d-%m-%Y')\n",
    "    brexit_economy_df['Date'] = formatted_date\n",
    "    \n",
    "\n",
    "    return brexit_economy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af10fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date list for scraping historical data \n",
    "\n",
    "dates_list = [\n",
    "    \"19/02/2024\",\"12/02/2024\",\"05/02/2024\",\"29/01/2024\",\"22/01/2024\",\"15/01/2024\",\"11/12/2023\",\"04/12/2023\",\"27/11/2023\",\n",
    "    \"20/11/2023\",\"13/11/2023\",\"06/11/2023\", \"30/10/2023\",\"23/10/2023\",\"16/10/2023\", \"06/10/2023\",\"03/10/2023\",\"25/09/2023\",\n",
    "    \"19/09/2023\",\"04/09/2023\",\"29/08/2023\",\"21/08/2023\",\"14/08/2023\",\"07/08/2023\",\"31/07/2023\",\"24/07/2023\",\"17/07/2023\",\n",
    "    \"10/07/2023\",\"03/07/2023\",\"26/06/2023\",\"19/06/2023\",\"12/06/2023\",\"06/06/2023\",\"24/05/2023\",\"15/05/2023\",\"09/05/2023\",\n",
    "    \"02/05/2023\",\"27/04/2023\",\"18/04/2023\",\"03/04/2023\",\"27/03/2023\",\"20/03/2023\",\"13/03/2023\",\"07/03/2023\",\"27/02/2023\", \"21/02/2023\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57451ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop to scrape date list and get historical economy data\n",
    "\n",
    "brexit_economy_df = pd.DataFrame()\n",
    "\n",
    "# Loop through the dates list and process each date\n",
    "for date_str in dates_list:\n",
    "    try:\n",
    "        # Call the function to get brexit data for the current date\n",
    "        data_entry = get_brexit_and_economy_delta_data(date_str)\n",
    "        \n",
    "        # Append the current date's data to the combined DataFrame\n",
    "        brexit_economy_df = brexit_economy_df.append(data_entry, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for date: {date_str}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to get brexit and economy from data urls in order to catch any data releases that previous code didn't get\n",
    "\n",
    "\n",
    "def get_brexit_and_economy_delta_data_url(date_str, url):\n",
    "   \n",
    "    # Construct PDF URL\n",
    "    pdf_url = url\n",
    "    #  # Retrieve PDF content\n",
    "    response = requests.get(pdf_url)\n",
    "    pdf_file = PdfReader(BytesIO(response.content))\n",
    "    page_text = pdf_file.pages[-1].extract_text()\n",
    "\n",
    "    # Split text into sections\n",
    "    sections = page_text.split('\\n')\n",
    "\n",
    "    # Trim data\n",
    "    trimmed_data = []\n",
    "    for item in sections:\n",
    "        if 'Excluding' in item:\n",
    "            break\n",
    "        trimmed_data.append(item)\n",
    "\n",
    "    trimmed_data = [item for item in trimmed_data if any(char.isdigit() for char in item)]\n",
    "\n",
    "    # Initialize lists to hold extracted data\n",
    "    conservative_number = []\n",
    "    labour_number = []\n",
    "    dont_know_economy = []\n",
    "    stay_out_eu = []\n",
    "    rejoin_eu = []\n",
    "    dont_know_brexit = []\n",
    "\n",
    "    # Extract data\n",
    "    for item in trimmed_data:\n",
    "        if 'Exchequer' in item:\n",
    "            number = ''.join(filter(str.isdigit, item))\n",
    "            if not conservative_number:\n",
    "                conservative_number.append(number)\n",
    "            else:\n",
    "                labour_number.append(number)\n",
    "        elif \"Don't know\" in item:\n",
    "            number = ''.join(filter(str.isdigit, item))\n",
    "            if not dont_know_economy:\n",
    "                dont_know_economy.append(number)\n",
    "            else:\n",
    "                dont_know_brexit.append(number)\n",
    "        elif 'European Union' in item:\n",
    "            number = ''.join(filter(str.isdigit, item))\n",
    "            if not stay_out_eu:\n",
    "                stay_out_eu.append(number)\n",
    "            else:\n",
    "                rejoin_eu.append(number)\n",
    "\n",
    "    # Create data dictionaries\n",
    "    brexit_economy_data = {\n",
    "        'Conservatives/Rishi Sunak/Jeremy Hunt': conservative_number,\n",
    "        'Labour/Keir Starmer/Rachel Reeves': labour_number,\n",
    "        'Don\\'t Know econ': dont_know_economy,\n",
    "        'Rejoin EU': rejoin_eu,\n",
    "        'Stay Out EU': stay_out_eu,\n",
    "        'Don\\'t Know brex': dont_know_brexit\n",
    "    }\n",
    "\n",
    "    # Create dataframes\n",
    "    brexit_economy_df = pd.DataFrame(brexit_economy_data)\n",
    "    brexit_economy_df['Conservatives/Rishi Sunak/Jeremy Hunt'] = pd.to_numeric(brexit_economy_df['Conservatives/Rishi Sunak/Jeremy Hunt'])\n",
    "    brexit_economy_df['Labour/Keir Starmer/Rachel Reeves'] = pd.to_numeric(brexit_economy_df['Labour/Keir Starmer/Rachel Reeves'])\n",
    "    brexit_economy_df['Don\\'t Know econ'] = pd.to_numeric(brexit_economy_df['Don\\'t Know econ'])\n",
    "    brexit_economy_df['Stay Out EU'] =  pd.to_numeric(brexit_economy_df['Stay Out EU'])\n",
    "    brexit_economy_df['Rejoin EU'] =  pd.to_numeric(brexit_economy_df['Rejoin EU'])\n",
    "    brexit_economy_df['Don\\'t Know brex'] =  pd.to_numeric(brexit_economy_df['Don\\'t Know brex'])\n",
    "\n",
    "    # Add Date column to dataframes\n",
    "    date = pd.to_datetime(date_str)\n",
    "    formatted_date = date.strftime('%d-%m-%Y')\n",
    "    brexit_economy_df['Date'] = formatted_date\n",
    "    \n",
    "\n",
    "    return brexit_economy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe0af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape data using urls: NB this code is only for setting up the historical dataset:see below for adding one new url\n",
    "\n",
    "date_urls = [\n",
    "    (\"23/10/2023\", \"https://deltapoll.co.uk/wp-content/uploads/2023/10/Deltapoll-231020_trackers.pdf\"),\n",
    "    (\"03/10/2023\", 'https://deltapoll.co.uk/wp-content/uploads/2023/10/Deltapoll-231002_trackers.pdf'),\n",
    "    (\"19/09/2023\", \"https://deltapoll.co.uk/wp-content/uploads/2023/09/Deltapoll-230918_trackers.pdf\"),\n",
    "    (\"06/06/2023\", \"https://deltapoll.co.uk/wp-content/uploads/2023/05/Deltapoll-230606_trackers.pdf\"),\n",
    "    (\"24/05/2023\", \"https://deltapoll.co.uk/wp-content/uploads/2023/05/Deltapoll-230523_trackers.pdf\"),\n",
    "    (\"18/04/2023\", \"https://deltapoll.co.uk/wp-content/uploads/2023/04/Deltapoll-230417_trackers.pdf\"),\n",
    "    (\"21/02/2023\", \"https://deltapoll.co.uk/wp-content/uploads/2023/02/Deltapoll-230220_trackers_1.pdf\")\n",
    "]\n",
    "\n",
    "brexit_economy_df_url = pd.DataFrame()\n",
    "\n",
    "for date, url in date_urls:\n",
    "    try:\n",
    "        # Call the function to get brexit data for the current date\n",
    "        brexit_economy_url = get_brexit_and_economy_delta_data_url(date, url)\n",
    "        # Append the current date's data to the combined DataFrame\n",
    "        brexit_economy_df_url = brexit_economy_df_url.append(brexit_economy_url, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for date: {date}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        continue\n",
    "        \n",
    "brexit_economy_df = pd.concat([brexit_economy_df, brexit_economy_df_url], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "id": "20609296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dataframe by date\n",
    "\n",
    "brexit_economy_df['Date'] = pd.to_datetime(brexit_economy_df['Date'])\n",
    "brexit_economy_df = brexit_economy_df.sort_values(by='Date')\n",
    "brexit_economy_df['Date'] = brexit_economy_df['Date'].dt.strftime('%d-%m-%Y')\n",
    "#flip so nearest date at top: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0fdd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to add one new entry by date\n",
    "\n",
    "#brexit_economy_entry = get_brexit_and_economy_data_delta(date)\n",
    "#brexit_economy_df = brexit_economy_df.append(brexit_economy_entry)\n",
    "\n",
    "# code to add one new entry by url\n",
    "\n",
    "#brexit_economy_url = get_brexit_and_economy_data_delta_url(date, url)\n",
    "#brexit_economy_df = brexit_economy_df.append(brexit_economy_url, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a6042c",
   "metadata": {},
   "source": [
    "# Voter satisfaction and economic optimism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db849cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polmon_data_from_pdf(date_of_publish_str, date_str):\n",
    "    # Define the convert_date_format function\n",
    "    def convert_date_format(date_of_publish_str):\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_of_publish_str[:3]\n",
    "        year_str = '20' + date_of_publish_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its numerical representation\n",
    "        month_dict = {'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04', 'May': '05', 'Jun': '06', \n",
    "                      'Jul': '07', 'Aug': '08', 'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'}\n",
    "        month_numeric = month_dict[month_str]\n",
    "\n",
    "        # Format the date into 'YYYY-MM' format\n",
    "        formatted_date = f'{year_str}-{month_numeric}'\n",
    "        return formatted_date\n",
    "    \n",
    "    def convert_date_str_to_mmm_yy(date_str): #1: Jan24 -> jan24\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_str[:3]\n",
    "        year_str = date_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its full name\n",
    "        month_dict_lower = {'Jan': 'jan', 'Feb': 'feb', 'Mar': 'mar', 'Apr': 'apr', 'May': 'may', 'Jun': 'jun', \n",
    "                  'Jul': 'jul', 'Aug': 'aug', 'Sep': 'sep', 'Oct': 'october', 'Nov': 'nov', 'Dec': 'dec'}\n",
    "        month_lower = month_dict_lower[month_str]\n",
    "\n",
    "        # Format the date into 'mmm-year' format\n",
    "        formatted_date_lower = f'{month_lower}{year_str}'\n",
    "        return formatted_date_lower\n",
    "    \n",
    "    def convert_date_str_to_month_yy(date_str): #2 Jan24 -> january24\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_str[:3]\n",
    "        year_str = date_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its full name\n",
    "        month_dict_lower = {'Jan': 'january', 'Feb': 'february', 'Mar': 'march', 'Apr': 'april', 'May': 'may', 'Jun': 'june', \n",
    "                  'Jul': 'july', 'Aug': 'august', 'Sep': 'september', 'Oct': 'oct', 'Nov': 'november', 'Dec': 'december'}\n",
    "        month_full_name_lower = month_dict_lower[month_str]\n",
    "\n",
    "        # Format the date into 'month-year' format\n",
    "        formatted_date_lower = f'{month_full_name_lower}{year_str}'\n",
    "        return formatted_date_lower\n",
    "    \n",
    "    def convert_date_str_to_Month_yy(date_str): #3 Jan24 -> January24\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_str[:3]\n",
    "        year_str = date_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its full name\n",
    "        month_dict_upper = {'Jan': 'January', 'Feb': 'February', 'Mar': 'March', 'Apr': 'April', 'May': 'May', 'Jun': 'June', \n",
    "                  'Jul': 'July', 'Aug': 'August', 'Sep': 'September', 'Oct': 'October', 'Nov': 'November', 'Dec': 'December'}\n",
    "        month_full_name_upper = month_dict_upper[month_str]\n",
    "\n",
    "        # Format the date into 'Month-Year' format\n",
    "        formatted_date_upper = f'{month_full_name_upper}{year_str}'\n",
    "        return formatted_date_upper\n",
    "    \n",
    "    def convert_date_str_to_mmm_year(date_str): #4 Jan24 -> jan2024\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_str[:3]\n",
    "        year_str = '20' + date_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its full name\n",
    "        month_dict_lower = {'Jan': 'jan', 'Feb': 'feb', 'Mar': 'mar', 'Apr': 'apr', 'May': 'may', 'Jun': 'jun', \n",
    "                  'Jul': 'jul', 'Aug': 'aug', 'Sep': 'sep', 'Oct': 'october', 'Nov': 'nov', 'Dec': 'dec'}\n",
    "        month_lower = month_dict_lower[month_str]\n",
    "\n",
    "        # Format the date into 'month-year' format\n",
    "        formatted_date_lower = f'{month_lower}{year_str}'\n",
    "        return formatted_date_lower\n",
    "    \n",
    "    def convert_date_str_to_Mmm_year(date_str): #5 Jan24 -> Jan2024\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_str[:3]\n",
    "        year_str = '20' + date_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its full name\n",
    "        month_dict_upper = {'Jan': 'Jan', 'Feb': 'Feb', 'Mar': 'Mar', 'Apr': 'Apr', 'May': 'May', 'Jun': 'Jun', \n",
    "                  'Jul': 'Jul', 'Aug': 'Aug', 'Sep': 'Sep', 'Oct': 'Oct', 'Nov': 'Nov', 'Dec': 'Dec'}\n",
    "        month_upper = month_dict_upper[month_str]\n",
    "\n",
    "        # Format the date into 'Month-Year' format\n",
    "        formatted_date_upper = f'{month_upper}{year_str}'\n",
    "        return formatted_date_upper\n",
    "\n",
    "    def convert_date_str_to_month_year(date_str): #6 Jan24 -> january2024\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_str[:3]\n",
    "        year_str = '20' + date_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its full name\n",
    "        month_dict_lower = {'Jan': 'january', 'Feb': 'february', 'Mar': 'march', 'Apr': 'april', 'May': 'may', 'Jun': 'june', \n",
    "                  'Jul': 'july', 'Aug': 'august', 'Sep': 'september', 'Oct': 'october', 'Nov': 'november', 'Dec': 'december'}\n",
    "        month_full_name_lower = month_dict_lower[month_str]\n",
    "\n",
    "        # Format the date into 'month-year' format\n",
    "        formatted_date_lower = f'{month_full_name_lower}{year_str}'\n",
    "        return formatted_date_lower\n",
    "        \n",
    "    def convert_date_str_to_Month_year(date_str): #7 Jan24 -> January2024\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_str[:3]\n",
    "        year_str = '20' + date_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its full name\n",
    "        month_dict_upper = {'Jan': 'January', 'Feb': 'February', 'Mar': 'March', 'Apr': 'April', 'May': 'May', 'Jun': 'June', \n",
    "                  'Jul': 'July', 'Aug': 'August', 'Sep': 'September', 'Oct': 'October', 'Nov': 'November', 'Dec': 'December'}\n",
    "        month_full_name_upper = month_dict_upper[month_str]\n",
    "\n",
    "        # Format the date into 'Month-Year' format\n",
    "        formatted_date_upper = f'{month_full_name_upper}{year_str}'\n",
    "        return formatted_date_upper\n",
    "    \n",
    "    \n",
    "    def convert_date_str_to_month_dash_year (date_str): #8 Jan24 -> january-2024\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_str[:3]\n",
    "        year_str = '20' + date_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its full name\n",
    "        month_dict_lower = {'Jan': 'january', 'Feb': 'february', 'Mar': 'march', 'Apr': 'april', 'May': 'may', 'Jun': 'june', \n",
    "                  'Jul': 'july', 'Aug': 'august', 'Sep': 'september', 'Oct': 'october', 'Nov': 'november', 'Dec': 'december'}\n",
    "        month_full_name_lower = month_dict_lower[month_str]\n",
    "\n",
    "        # Format the date into 'month-year' format\n",
    "        formatted_date_lower = f'{month_full_name_lower}-{year_str}'\n",
    "        return formatted_date_lower\n",
    "    \n",
    "    def convert_date_str_to_mmm_dash_year (date_str): #9 Jan24 -> jan-2024\n",
    "        # Parse the month and year from the input date string\n",
    "        month_str = date_str[:3]\n",
    "        year_str = '20' + date_str[-2:]\n",
    "\n",
    "        # Convert the month abbreviation to its full name\n",
    "        month_dict_lower = {'Jan': 'jan', 'Feb': 'feb', 'Mar': 'mar', 'Apr': 'apr', 'May': 'may', 'Jun': 'jun', \n",
    "                  'Jul': 'jul', 'Aug': 'aug', 'Sep': 'sep', 'Oct': 'oct', 'Nov': 'nov', 'Dec': 'dec'}\n",
    "        month_lower = month_dict_lower[month_str]\n",
    "\n",
    "        # Format the date into 'month-year' format\n",
    "        formatted_date_lower = f'{month_lower}-{year_str}'\n",
    "        return formatted_date_lower\n",
    "    \n",
    "    # Convert date_of publish_str to 'YYYY-MM' format\n",
    "    formatted_date_of_publish_str = convert_date_format(date_of_publish_str)\n",
    "    \n",
    "    # Convert date_str to MM/YYYY format for the date column of data frame\n",
    "    date_obj = datetime.strptime(date_str, '%b%y')\n",
    "    formatted_date_str = date_obj.strftime('%m/%Y')\n",
    "    \n",
    "    # Convert date_str into all different formats for scraping \n",
    "    date_str_lower_year = convert_date_str_to_mmm_year(date_str) # Jan24 -> jan2024\n",
    "    date_str_lower_full_month_year = convert_date_str_to_month_year(date_str) #Jan24 -> january2024\n",
    "    date_str_full_month_year = convert_date_str_to_Month_year(date_str) #Jan24 -> January2024\n",
    "    date_str_upper_year = convert_date_str_to_Mmm_year(date_str) #Jan24 -> Jan2024\n",
    "    date_str_lower_yy = convert_date_str_to_mmm_yy(date_str) #Jan24 -> jan24\n",
    "    date_str_lower_full_month_yy = convert_date_str_to_month_yy(date_str) #Jan24 -> january24\n",
    "    date_str_full_month_yy = convert_date_str_to_Month_yy(date_str) #Jan24 -> January24\n",
    "    date_str_lower_full_month_dash_year = convert_date_str_to_month_dash_year(date_str) #Jan24 -> january-2024\n",
    "    date_str_lower_dash_year = convert_date_str_to_mmm_dash_year(date_str) #Jan24 -> jan-2024\n",
    "\n",
    "    # List of possible URL formats\n",
    "    url_formats = [\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/Ipsos%20,\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str}_Issues%20Index_topline_PUBLIC_0.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_lower_year}_Issues%20Index_topline_PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_lower_full_month_year}_Issues%20Index_topline_PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_full_month_year}_Issues%20Index_topline_PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_upper_year}_Issues%20Index_topline_PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_lower_yy}_Issues%20Index_topline_PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_lower_full_month_yy}_Issues%20Index_topline_PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_full_month_yy}_Issues%20Index_topline_PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/ipsos-issues-index-{date_str_lower_full_month_dash_year}-topline.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/ipsos-issues-index-{date_str_lower_full_month_dash_year}-topline-PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/ipsos-issues-index-{date_str_lower_dash_year}-topline.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/ipsos-issues-index-{date_str_lower_dash_year}-topline-PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/ipsos-issues-index-topline-{date_str_lower_dash_year}.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/ipsos-issues-index-topline-{date_str_lower_full_month_dash_year}.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/issues-index-{date_str_lower_full_month_dash_year}-topline.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/issues-index-{date_str_lower_dash_year}-topline.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/issues-index-{date_str_lower_full_month_dash_year}-topline-PUBLIC.pdf',  \n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/issues-index-{date_str_lower_dash_year}-topline-PUBLIC.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/issues-index-topline-{date_str_lower_dash_year}.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/issues-index-topline-{date_str_lower_full_month_dash_year}.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str}_issues_index_topline_public.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str}_issues_index_topline.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_lower_year}_issues_index_topline_public.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_lower_full_month_year}_issues_index_topline_public.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_full_month_year}_issues_index_topline_public.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_upper_year}_issues_index_topline_public.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_lower_yy}_issues_index_topline_public.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_lower_full_month_yy}_issues_index_topline_public.pdf',\n",
    "        f'https://www.ipsos.com/sites/default/files/ct/news/documents/{formatted_date_of_publish_str}/{date_str_full_month_yy}_issues_index_topline_public.pdf'\n",
    "    ]\n",
    "        \n",
    "        https://www.ipsos.com/sites/default/files/ct/news/documents/2023-10/Ipsos%20Oct%202023%20Political%20Monitor%20Charts_251023_PUBLIC_0.pdf\n",
    "            https://www.ipsos.com/sites/default/files/ct/news/documents/2023-09/Ipsos%20Sept%202023%20Political%20Monitor%20Charts_PUBLIC.pdf\n",
    "    \n",
    "    # Attempt to retrieve the PDF content from each URL\n",
    "    for pdf_url in url_formats:\n",
    "        response = requests.get(pdf_url)\n",
    "        if response.status_code == 200:\n",
    "            pdf_file = PyPDF2.PdfReader(BytesIO(response.content))\n",
    "            break  # Break out of the loop if PDF content is successfully retrieved\n",
    "    \n",
    "    # If PDF content couldn't be retrieved, handle the error or return None\n",
    "    else:\n",
    "        print(response.status_code, pdf_url)\n",
    "        return None\n",
    "    \n",
    "    # Get the PDF content\n",
    "    #response = requests.get(pdf_url)\n",
    "    #pdf_file = PyPDF2.PdfReader(BytesIO(response.content))\n",
    "    \n",
    "     # Extract text from each page of the PDF\n",
    "    for page_number in range(len(pdf_file.pages)):\n",
    "        page_text = pdf_file.pages[page_number].extract_text()\n",
    "    rows = [line.split() for line in page_text.split('\\n') if line.strip()]\n",
    "    rows = rows[10:]\n",
    "    \n",
    "    # Rearrange each sublist\n",
    "    def rearrange_sublist(sublist):\n",
    "        variable_names = ' '.join(sublist[:-2])\n",
    "        first_value = sublist[-2] if len(sublist) >= 2 else ''\n",
    "        second_value = sublist[-1] if len(sublist) >= 1 else ''\n",
    "        return [variable_names, first_value, second_value]\n",
    "\n",
    "    rearranged_data = [rearrange_sublist(sublist) for sublist in rows]\n",
    "\n",
    "    \n",
    "    # Convert the rearranged data into a DataFrame\n",
    "    df = pd.DataFrame(rearranged_data, columns=['Variable Names', 'Most important issue', 'One of the most important  issues'])\n",
    "    df = df.drop(columns=['Most important issue'])\n",
    "    df['Date'] = formatted_date_str  # Add a 'Date' column with the formatted date\n",
    "    df = df.pivot(columns='Variable Names', values='One of the most important  issues', index='Date')\n",
    "\n",
    "    # Reset the index to make 'Date' a column\n",
    "    df = df.reset_index()\n",
    "    df = df.rename_axis('Index', axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1247,
   "id": "44d736ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to get historical data\n",
    "\n",
    "data = {\n",
    "    \"Date\": [\n",
    "        \"July 2019\", \"Sep 2019\", \"Oct 2019\", \"Dec 2019\",\n",
    "        \"Jan 2020\", \"March 2020\", \"June 2020\", \"July 2020\",\n",
    "        \"Sept 2020\", \"Oct 2020\", \"Dec 2020\", \"Jan 2021\",\n",
    "        \"March 2021\", \"April 2021\", \"May 2021\", \"July 2021\",\n",
    "        \"July 2021\", \"September 2021\", \"Oct 2021\", \"Dec 2021\",\n",
    "        \"Jan 2022\", \"Mar 2022\", \"Apr 2022\", \"May 2022\",\n",
    "        \"June 2022\", \"July 2022\", \"Sept 2022\", \"Oct 2022\",\n",
    "        \"Nov 2022\", \"Dec 2022\", \"Jan 2023\", \"Feb 2023\",\n",
    "        \"March 2023\", \"May 2023\", \"June 2023\", \"July 2023\",\n",
    "        \"Sept 2023\", \"Oct 2023\", \"Nov 2023\", \"Dec 2023\",\n",
    "        \"Jan 2024\"],\n",
    "    \n",
    "    \"Government_Sat\": [18, 14, 19, 23, 40, 48, 40, 44, 35, 30, 37, 41, 42, 44, 44, 35, 39, 35, 29, 25,\n",
    "        25, 31, 30, 26, 23, 20, 20, 11, 16, 14, 14, 15, 16, 15, 12, 14, 12, 14, 13, 12, 13],\n",
    "    \n",
    "    \"Government_Dis\": [75, 81, 74, 72, 50, 41, 51, 48, 57, 61, 53, 51, 49, 51, 48, 55, 51, 51, 62, 65,\n",
    "        67, 59, 61, 66, 69, 74, 70, 80, 76, 79, 76, 77, 77, 76, 80, 79, 80, 80, 80, 82, 78],\n",
    "\n",
    "    \"Con_Leader_Sat\": [31, 37, 46, 36, 47, 52, 48, 47, 40, 33, 42, 42, 44, 44, 44, 38, 41, 39, 34, 28,\n",
    "        24, 31, 30, 28, 25, 24, 27, 16, 29, 28, 26, 27, 32, 30, 28, 26, 28, 26, 21, 21, 20],\n",
    "    \n",
    "    \"Con_Leader_Dis\": [38, 55, 44, 56, 44, 38, 49, 47, 54, 59, 50, 51, 51, 50, 47, 51, 52, 51, 61, 65,\n",
    "        70, 59, 63, 64, 69, 69, 29, 67, 49, 56, 59, 54, 59, 55, 63, 63, 66, 69, 66, 69, 66],\n",
    "    \n",
    "    \"Lab_Leader_Sat\": [19, 16, 15, 24, 16, 19, 51, 48, 43, 45, 38, 40, 33, 36, 22, 27, 27, 25, 29, 33,\n",
    "        27, 33, 32, 31, 32, 29, 31, 31, 36, 36, 37, 34, 31, 30, 31, 31, 31, 30, 30, 30, 30],\n",
    "    \n",
    "    \"Lab_Leader_Dis\": [69, 76, 75, 68, 75, 68, 20, 26, 27, 30, 33, 35, 42, 46, 51, 50, 53, 50, 50, 43,\n",
    "        42, 43, 46, 49, 48, 49, 50, 45, 42, 40, 40, 46, 51, 54, 50, 49, 48, 48, 51, 51, 48]\n",
    "}\n",
    "\n",
    "satisfaction_df = pd.DataFrame(data)\n",
    "# Subtracting disatisfied from satisfied to get net satisfaction\n",
    "satisfaction_df['Net_Government'] = satisfaction_df['Government_Sat'] - satisfaction_df['Government_Dis']\n",
    "satisfaction_df['Net_Con_Leader'] = satisfaction_df['Con_Leader_Sat'] - satisfaction_df['Con_Leader_Dis']\n",
    "satisfaction_df['Net_Lab_Leader'] = satisfaction_df['Lab_Leader_Sat'] - satisfaction_df['Lab_Leader_Dis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1314,
   "id": "603fc5b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "PdfReadError",
     "evalue": "EOF marker not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPdfReadError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1314-0efe411ca508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpdf_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://www.ipsos.com/sites/default/files/ct/news/documents/2024-01/ipsos-politicial-monitor-uk-charts-january-2024.pdf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpdf_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPdfReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpage_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdf_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/PyPDF2/_reader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, stream, strict, password)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/PyPDF2/_reader.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m   1413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mStreamType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_basic_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_eof_marker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1416\u001b[0m         \u001b[0mstartxref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_startxref_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/PyPDF2/_reader.py\u001b[0m in \u001b[0;36m_find_eof_marker\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m   1469\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"%%EOF\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlast_mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mPdfReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EOF marker not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_previous_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPdfReadError\u001b[0m: EOF marker not found"
     ]
    }
   ],
   "source": [
    "# code to update dataframe with new data\n",
    "\n",
    "pdf_url = 'https://www.ipsos.com/sites/default/files/ct/news/documents/2024-01/ipsos-politicial-monitor-uk-charts-january-2024.pdf'\n",
    "response = requests.get(pdf_url)\n",
    "pdf_file = PdfReader(BytesIO(response.content))\n",
    "page_text = pdf_file.pages[4].extract_text()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68511d4",
   "metadata": {},
   "source": [
    "# Economic optimism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "id": "9161cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Date\": [\n",
    "        \"Feb 2019\", \"March 2019\", \"May 2019\", \"June 2019\",\n",
    "        \"July 2019\", \"Sept 2019\", \"Oct 2019\", \"Dec 2019\",\n",
    "        \"Jan 2020\", \"March 2020\", \"June 2020\", \"July 2020\",\n",
    "        \"Sept 2020\", \"Oct 2020\", \"Dec 2020\", \"Jan 2021\",\n",
    "        \"March 2021\", \"April 2021\", \"May 2021\", \"July 2021\",\"August 2021\",\n",
    "        \"Sept 2021\", \"Oct 2021\", \"December 2021\", \"Jan 2022\",\n",
    "        \"March 2022\", \"Apr 2022\", \"May 2022\", \"June 2022\", \"July 2022\",\n",
    "        \"Sept 2022\", \"Oct 2022\", \"Nov 2022\", \"December 2022\", \"Jan 2023\",\n",
    "        \"Feb 2023\", \"March 2023\", \"May 2023\", \"June 2023\", \"July 2023\",\n",
    "        \"Sept 2023\", \"Oct 2023\", \"Nov 2023\", \"Dec 2023\", \"Jan 2024\"\n",
    "    ],\n",
    "    \"Improve\": [\n",
    "        14, 16, 16, 13, 18, 15, 17, 21, 29, 15, 22, 20, 21, 15, 27, 29, 43, 51, 53,\n",
    "    47, 44, 31, 28, 25, 27, 14, 14, 15, 13, 16, 15, 16, 16, 14, 24, 23, 22, 24,\n",
    "    21, 28, 20, 21, 19, 22, 24\n",
    "    ],\n",
    "    \n",
    "    \"Stay the same\": [ 21, 20, 25, 23, 19, 20, 19, 20, 21, 13, 6, 9, 10, 10, 7, 9, 14, 11, 13, 12,\n",
    "    12, 13, 17, 19, 13, 7, 12, 10, 8, 10, 10, 11, 10, 14, 16, 12, 17, 18, 18, 15,\n",
    "    23, 20, 21, 24, 21],\n",
    "    \n",
    "    \"Get worse\": [\n",
    "        57, 58, 51, 57, 58, 59, 56, 50, 42, 69, 69, 68, 66, 71, 63, 60, 41, 36, 31,\n",
    "    36, 39, 53, 54, 52, 56, 76, 70, 72, 77, 69, 71, 70, 72, 69, 57, 61, 58, 54,\n",
    "    58, 55, 55, 55, 55, 50, 50],\n",
    "    \n",
    "    \"Don't know\": [ 9, 6, 9, 7, 5, 6, 8, 9, 7, 3, 3, 2, 3, 4, 4, 2, 3, 2, 4, 5,\n",
    "    5, 3, 2, 4, 3, 4, 4, 3, 2, 5, 3, 3, 3, 3, 3, 4, 3, 4, 3, 3,\n",
    "    2, 5, 5, 4, 5],\n",
    "    \n",
    "    \"EOI\": [\n",
    "        -43, -42, -35, -44, -40, -44, -39, -29, -13, -54, -47, -48, -45, -56,\n",
    "    -36, -31, 2, 15, 22, 11, 5, -22, -26, -27, -29, -62, -56, -57, -64,\n",
    "    -53, -56, -54, -56, -55, -33, -38, -36, -30, -37, -27, -35, -34, -36,\n",
    "    -28, -26]}\n",
    "\n",
    "econ_optimism_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "id": "3efa45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for updating every month"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
